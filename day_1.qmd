---
title: "Reproducible & Collaborative Workflows"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Day 1

| **Time (PST)**    | **Activity**                                                             |
|-------------------|--------------------------------------------------------------------------|
| 10:00am - 10:50am | *Introduction & Reproducible workflows (50 min)*                                |
| 10:50am - 11:00am | *Break (10 min)*                                                         |
| 11:00am - 12:30pm | *Interactive Session: Drawing board + reporting (60 min); git recap (30min)*    |
| 12:30pm - 1:30pm  | *Lunch*                                                                  |
| 1:30pm - 2:00pm   | *Collaborative workflows: Fork and Branches (30 min)*                     |
| 2:00pm - 3:00pm   | *Interactive Session: Collaborating with GitHub (60 min)*                |
| 3:00pm - 3:10pm   | *Break (10 min)*                                                         |
| 3:10pm - 4:00pm   | *git conflicts  (50 min)*                                                |


# Morning

## Introduction to EDS-214

[**A few words...**](https://docs.google.com/presentation/d/e/2PACX-1vQoawMQwTyWma4JsDePgainH7WNrRGWBEBVm794FCjrp6gyYoi6RrfBDJM5thJCLy4GAqJES8AR-5GB/pub?start=false&loop=false&delayms=3000)


## Reproducible Analytical Workflows

####  Why going reproducible ?

There are many reasons why it is essential to make your science reproducible and how the necessity of openness is a cornerstone of the integrity and efficacy of the scientific research process. Here we will also be focusing on why making your work reproducible will empower **you** to iterate quickly, integrate new information more easily to iterate quickly, scale your analysis to larger data sets, and better collaborate by receiving feedback and contributions from others, as well as enable your "future self" to reuse and build from your own work.

To make your data-riven research reproducible, it is important to develop scientific workflows that will be relying on **programming** to accomplish the necessary tasks to go from the raw data to the results (figures, new data, publications, ...) of your analysis. Scripting languages, even better open ones, such as `R` and `python`, are well-suited for scientists to develop reproducible scientific workflows. Those scripting languages provide a large ecosystem of libraries (also referred to as packages or modules) that are ready to be leveraged to conduct analysis and modeling. In this course we will introduce how to use `R`, `git` and `GitHub` to develop such workflows as a team.


```{r tidy-workflow, out.width='80%', fig.align="center", fig.cap="Workflow example using the `tidyverse`. Note the program box around the workflow and the iterative nature of the analytical process described. _Source: R for Data Science <https://r4ds.had.co.nz/>_",echo=FALSE}
  knitr::include_graphics(here::here("img","tidy-workflow.png"))
```

**Two points to stress about this figure**:

- Workflows are rarely linear... even less so their implementation
- Note the programming box -- yes, you'll need to code this :) 

***Workflows are developed iteratively, and one of the most helpful things you can do as a data scientist is to talk about them with your research team.***



## Lecture 1: Definitions and Concepts

[**Slide deck**](https://docs.google.com/presentation/d/e/2PACX-1vRO81O7IJeTHihyMu6yXTsHhWozBbTWWVHy9YJ2ytilrOBji24dzhDTMilQc0hna9prfXLlsLnafa1B/pub?start=false&loop=false&delayms=60000)




## Hands-on: Planing things

**Donâ€™t start implementing nor coding without planning!** It is important to stress that scientists write scripts to help them to investigate scientific question(s). Therefore scripting should not drive our analysis and thinking. We strongly recommend you take the time to plan ahead all the steps you need to conduct your analysis. Developing such a scientific workflow will help you to narrow down the tasks that are needed to move forward your analysis.

### From drawings to pseudocode

[Materials](day1-pseudocode.html)

![Cherubini et al., 2007](img/whiteborad_drawings.png)

### Hands-on

[Investigating the impacts of Hurricane on stream chemistry in Puerto Rico](day1-hands-on_drawings.html)

---

# Afternoon



---

# Further reading

Here are a few selected publications to help you to learn more about these topics.


## Data and scientific workflow management:

- The Practice of Reproducible Research-Case Studies and Lessons from the Data-Intensive Sciences:\
    Kitzes, Justin, Daniel Turek, and Fatma Deniz. n.d. <http://www.practicereproducibleresearch.org/>
- Good enough practices in Scientific Computing: \
    [https://doi.org/10.1371/journal.pcbi.1005510](https://doi.org/10.1371/journal.pcbi.1005510) 
- Script your analysis:   \
    [https://doi.org/10.1038/nj7638-563a](https://doi.org/10.1038/nj7638-563a) 
- Principles for data analysis workflows:   \
    <https://doi.org/10.1371/journal.pcbi.1008770>
- Benureau, F.C.Y., Rougier, N.P., 2018. Re-run, Repeat, Reproduce, Reuse, Replicate: Transforming Code into Scientific Contributions. Front. Neuroinform. 0. https://doi.org/10.3389/fninf.2017.00069
- Sandve, G.K., Nekrutenko, A., Taylor, J., Hovig, E., 2013. Ten Simple Rules for Reproducible Computational Research. PLOS Computational Biology 9, e1003285. https://doi.org/10.1371/journal.pcbi.1003285
- Some Simple Guidelines for Effective Data Management: \
    [https://doi.org/10.1890/0012-9623-90.2.205](https://doi.org/10.1890/0012-9623-90.2.205) 
- Basic concepts of data management: \
    [https://www.dataone.org/education-modules](https://www.dataone.org/education-modules)


## Open Science

- The Tao of open science for ecology:  \
[https://doi.org/10.1890/ES14-00402.1](https://doi.org/10.1890/ES14-00402.1) 
- Challenges and Opportunities of Open Data in Ecology:  \
[https://doi.org/10.1126/science.1197962](https://doi.org/10.1126/science.1197962)  
- Scientific computing: Code alert \
[https://doi.org/10.1038/nj7638-563a](https://doi.org/10.1038/nj7638-563a) 
- Our path to better science in less time using open data science tools \
[https://doi.org/10.1038%2Fs41559-017-0160](https://doi.org/10.1038%2Fs41559-017-0160)
-  FAIR data guiding principles \
[https://doi.org/10.1038/sdata.2016.18](https://doi.org/10.1038/sdata.2016.18) 
- Skills and Knowledge for Data-Intensive Environmental Research [https://doi.org/10.1093/biosci/bix025](https://doi.org/10.1093/biosci/bix025)  
- Let go your data \
[https://doi.org/10.1038/s41563-019-0539-5](https://doi.org/10.1038/s41563-019-0539-5) 



