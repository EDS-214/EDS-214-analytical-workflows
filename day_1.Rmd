---
title: "Reproducible & collaborative workflows"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Lecture 1: Definitions and Concepts

[**Slide deck**](https://docs.google.com/presentation/d/e/2PACX-1vRO81O7IJeTHihyMu6yXTsHhWozBbTWWVHy9YJ2ytilrOBji24dzhDTMilQc0hna9prfXLlsLnafa1B/pub?start=false&loop=false&delayms=60000)

# Why going reproducible

There are many reasons why it is essential to make your science reproducible and how the necessity of openness is a cornerstone of the integrity and efficacy of the scientific research process. Here we will also be focusing on why making your work reproducible will empower **you** to iterate quickly, integrate new information more easily to iterate quickly, scale your analysis to larger data sets, and better collaborate by receiving feedback and contributions from others, as well as enable your "future self" to reuse and build from your own work.

To make your data-riven research reproducible, it is important to develop scientific workflows that will be relying on **programming** to accomplish the necessary tasks to go from the raw data to the results (figures, new data, publications, ...) of your analysis. Scripting languages, even better open ones, such as `R` and `python`, are well-suited for scientists to develop reproducible scientific workflows. Those scripting languages provide a large ecosystem of libraries (also referred to as packages or modules) that are ready to be leveraged to conduct analysis and modeling. In this course we will introduce how to use `R`, `git` and `GitHub` to develop such workflows as a team.


```{r tidy-workflow, out.width='80%', fig.align="center", fig.cap="Workflow example using the `tidyverse`. Note the program box around the workflow and the iterative nature of the analytical process described. _Source: R for Data Science <https://r4ds.had.co.nz/>_",echo=FALSE}
  knitr::include_graphics(here::here("img","tidy-workflow.png"))
```

### Two points to stress about this figure:

- Workflows are not linear
- Programming box (yes, you'll need to code this!!)

**Workflows are rarely linear! They are developed iteratively, and one of the most helpful things you can do is talk about them with your research team.**

## How

We recommend shying away from spreadsheets as an analytical tool, as well as Graphical User Interfaces (GUI) where you need to click on buttons to do your analysis. Although convenient for data exploration, GUI will limit the reproducibility and the scalability of your analysis as human intervention is needed at every step. Spreadsheets can be useful to store tabular data, but it is recommended to script their analysis, as copy-pasting and references to cells are prone to mistake [(see Reinhart and Rogof example)](http://www.peri.umass.edu/fileadmin/pdf/working_papers/working_papers_301-350/WP322.pdf). It is also very difficult to track changes and to scale your analysis using spreadsheets. In addition, auto-formatting (number, date, character, ...) can silently introduce modifications to your data (e.g. [One in five genetics papers contains errors thanks to Microsoft Excel](https://www.sciencemag.org/news/2016/08/one-five-genetics-papers-contains-errors-thanks-microsoft-excel) ).



## Further reading

Here are a few selected publications to help you to learn more about these topics.

*   Data and scientific workflow management:
    *   Some Simple Guidelines for Effective Data Management: \
    [https://doi.org/10.1890/0012-9623-90.2.205](https://doi.org/10.1890/0012-9623-90.2.205) 
    *   Basic concepts of data management: \
    [https://www.dataone.org/education-modules](https://www.dataone.org/education-modules)
    *   Good enough practices in Scientific Computing: \
    [https://doi.org/10.1371/journal.pcbi.1005510](https://doi.org/10.1371/journal.pcbi.1005510) 
    *   Script your analysis:   \
    [https://doi.org/10.1038/nj7638-563a](https://doi.org/10.1038/nj7638-563a) 
    *   Principles for data analysis workflows:   \
    <https://doi.org/10.1371/journal.pcbi.1008770>


*   Open Science:
    *   The Tao of open science for ecology:  \
[https://doi.org/10.1890/ES14-00402.1](https://doi.org/10.1890/ES14-00402.1) 
    *   Challenges and Opportunities of Open Data in Ecology:  \
[https://doi.org/10.1126/science.1197962](https://doi.org/10.1126/science.1197962)  
    *   Scientific computing: Code alert \
[https://doi.org/10.1038/nj7638-563a](https://doi.org/10.1038/nj7638-563a) 
    *   Our path to better science in less time using open data science tools \
[https://doi.org/10.1038%2Fs41559-017-0160](https://doi.org/10.1038%2Fs41559-017-0160)
    *   FAIR data guiding principles \
[https://doi.org/10.1038/sdata.2016.18](https://doi.org/10.1038/sdata.2016.18) 
    *   Skills and Knowledge for Data-Intensive Environmental Research [https://doi.org/10.1093/biosci/bix025](https://doi.org/10.1093/biosci/bix025)  
    *   Let go your data \
[https://doi.org/10.1038/s41563-019-0539-5](https://doi.org/10.1038/s41563-019-0539-5) 
