---
title: "Reproducible & Collaborative Workflows"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Day 1

| **Time (PST)**    | **Activity**                        |
|-------------------|-------------------------------------|
| 9:00am - 9:50am  | *Intro & Reproducible and Collaborative workflow (50 min)*|
| 9:50am - 10:00am | *Break 1 (10 min)*                                        |
| 10:00am - 11:00am | *Interactive Session: Drawing board + reporting (60 min)* |
| 11:30am - 12:00am | *Flex time 1: Intro to MEDS Analytical server (Kat) (60 min)* |
| 12:00pm - 1:15pm  | *Lunch (75 min)*                                          |
| 1:15pm - 2:05pm   | *Working on a remote server (50 min)*                   |
| 2:15pm - 2:25pm   | *Break 2 (10 min)*                                        |
| 2:25pm - 3:25pm   | *RStudio server & the command line (60min)*             |
| 3:25pm - 3:35pm   | *Recap of the day (10 min)*                                  |
| 3:35pm - 5:00pm   | *Q&A Support with Casey (30 min)*                        |


# Introduction

[**A few words...**](https://docs.google.com/presentation/d/e/2PACX-1vQoawMQwTyWma4JsDePgainH7WNrRGWBEBVm794FCjrp6gyYoi6RrfBDJM5thJCLy4GAqJES8AR-5GB/pub?start=false&loop=false&delayms=3000)


# Reproducible Workflows

## Lecture 1: Definitions and Concepts

[**Slide deck**](https://docs.google.com/presentation/d/e/2PACX-1vRO81O7IJeTHihyMu6yXTsHhWozBbTWWVHy9YJ2ytilrOBji24dzhDTMilQc0hna9prfXLlsLnafa1B/pub?start=false&loop=false&delayms=60000)


###  Why going reproducible

There are many reasons why it is essential to make your science reproducible and how the necessity of openness is a cornerstone of the integrity and efficacy of the scientific research process. Here we will also be focusing on why making your work reproducible will empower **you** to iterate quickly, integrate new information more easily to iterate quickly, scale your analysis to larger data sets, and better collaborate by receiving feedback and contributions from others, as well as enable your "future self" to reuse and build from your own work.

To make your data-riven research reproducible, it is important to develop scientific workflows that will be relying on **programming** to accomplish the necessary tasks to go from the raw data to the results (figures, new data, publications, ...) of your analysis. Scripting languages, even better open ones, such as `R` and `python`, are well-suited for scientists to develop reproducible scientific workflows. Those scripting languages provide a large ecosystem of libraries (also referred to as packages or modules) that are ready to be leveraged to conduct analysis and modeling. In this course we will introduce how to use `R`, `git` and `GitHub` to develop such workflows as a team.


```{r tidy-workflow, out.width='80%', fig.align="center", fig.cap="Workflow example using the `tidyverse`. Note the program box around the workflow and the iterative nature of the analytical process described. _Source: R for Data Science <https://r4ds.had.co.nz/>_",echo=FALSE}
  knitr::include_graphics(here::here("img","tidy-workflow.png"))
```

**Two points to stress about this figure**:

- Workflows are rarely linear... even less so their implementation
- Note the programming box -- yes, you'll need to code this :) 

**Workflows are developed iteratively, and one of the most helpful things you can do as a data scientist is to talk about them with your research team.**

### How

We recommend shying away from spreadsheets as an analytical tool, as well as Graphical User Interfaces (GUI) where you need to click on buttons to do your analysis. Although convenient for data exploration, GUI will limit the reproducibility and the scalability of your analysis as human intervention is needed at every step. Spreadsheets can be useful to store tabular data, but it is recommended to script their analysis, as copy-pasting and references to cells are prone to mistake [(see Reinhart and Rogof example)](http://www.peri.umass.edu/fileadmin/pdf/working_papers/working_papers_301-350/WP322.pdf). It is also very difficult to track changes and to scale your analysis using spreadsheets. In addition, auto-formatting (number, date, character, ...) can silently introduce modifications to your data (e.g. [One in five genetics papers contains errors thanks to Microsoft Excel](https://www.sciencemag.org/news/2016/08/one-five-genetics-papers-contains-errors-thanks-microsoft-excel)).



## Hands-on: Planing things

**Donâ€™t start implementing nor coding without planning!** It is important to stress that scientists write scripts to help them to investigate scientific question(s). Therefore scripting should not drive our analysis and thinking. We strongly recommend you take the time to plan ahead all the steps you need to conduct your analysis. Developing such a scientific workflow will help you to narrow down the tasks that are needed to move forward your analysis.

### From drawings to pseudocode

[Materials](day1-pseudocode.html)

![Cherubini et al., 2007](img/whiteborad_drawings.png)

### Hands-on

[Investigating the impacts of Hurricane on stream chemistry in Puerto Rico](day1-hands-on_drawings.html)


---  

# Working on a remote server

## Learning Objectives

In this lesson, you will learn:

- How to connect to a remote server 
- Get familiar with RStudio server
- Get a short introduction to the command line (CLI)


## Why working on a remote machine?

Often the main motivation is to **scale your analysis beyond what a personal computer can handle**. R being pretty memory intensive, moving to a server often provides you more RAM and thus allows to load larger data in R without the need of slicing your data into chunks. But there are also other advantages, here are the main for scientist:

* **Power**: More *CPUs/Cores* (24/32/48), More RAM (256/384GB) 
* **Capacity**: More *disk space* and generally *faster storage* (in highly optimized RAID arrays)
* **Security**: Data are spread across *multiple drives* and have nightly *backups*
* **Collaboration**: *shared folders* for code, data, and other materials; same *software versions*

**=> The operating system is more likely going to be Linux!!**

**[Materials](day1-remote_server.html)**

![CERN computing center](https://cds.cern.ch/images/OPEN-PHO-CCC-2017-001-1/file?size=medium)

---

# Further reading

Here are a few selected publications to help you to learn more about these topics.


## Data and scientific workflow management:

- The Practice of Reproducible Research-Case Studies and Lessons from the Data-Intensive Sciences:\
    Kitzes, Justin, Daniel Turek, and Fatma Deniz. n.d. <http://www.practicereproducibleresearch.org/>
- Good enough practices in Scientific Computing: \
    [https://doi.org/10.1371/journal.pcbi.1005510](https://doi.org/10.1371/journal.pcbi.1005510) 
- Script your analysis:   \
    [https://doi.org/10.1038/nj7638-563a](https://doi.org/10.1038/nj7638-563a) 
- Principles for data analysis workflows:   \
    <https://doi.org/10.1371/journal.pcbi.1008770>
- Benureau, F.C.Y., Rougier, N.P., 2018. Re-run, Repeat, Reproduce, Reuse, Replicate: Transforming Code into Scientific Contributions. Front. Neuroinform. 0. https://doi.org/10.3389/fninf.2017.00069
- Sandve, G.K., Nekrutenko, A., Taylor, J., Hovig, E., 2013. Ten Simple Rules for Reproducible Computational Research. PLOS Computational Biology 9, e1003285. https://doi.org/10.1371/journal.pcbi.1003285
- Some Simple Guidelines for Effective Data Management: \
    [https://doi.org/10.1890/0012-9623-90.2.205](https://doi.org/10.1890/0012-9623-90.2.205) 
- Basic concepts of data management: \
    [https://www.dataone.org/education-modules](https://www.dataone.org/education-modules)


## Open Science

- The Tao of open science for ecology:  \
[https://doi.org/10.1890/ES14-00402.1](https://doi.org/10.1890/ES14-00402.1) 
- Challenges and Opportunities of Open Data in Ecology:  \
[https://doi.org/10.1126/science.1197962](https://doi.org/10.1126/science.1197962)  
- Scientific computing: Code alert \
[https://doi.org/10.1038/nj7638-563a](https://doi.org/10.1038/nj7638-563a) 
- Our path to better science in less time using open data science tools \
[https://doi.org/10.1038%2Fs41559-017-0160](https://doi.org/10.1038%2Fs41559-017-0160)
-  FAIR data guiding principles \
[https://doi.org/10.1038/sdata.2016.18](https://doi.org/10.1038/sdata.2016.18) 
- Skills and Knowledge for Data-Intensive Environmental Research [https://doi.org/10.1093/biosci/bix025](https://doi.org/10.1093/biosci/bix025)  
- Let go your data \
[https://doi.org/10.1038/s41563-019-0539-5](https://doi.org/10.1038/s41563-019-0539-5) 



